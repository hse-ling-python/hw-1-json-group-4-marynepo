{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Посчитать кол-во твитов\n",
    "\n",
    "Считываю файл, преобразовывая строки в питоновсие объекты. all_tweets - список твитов. Кол-во твитов - это длина этого списка.\n",
    "**Примечание - видимо, у меня старый питон, в open нет encoding, а вывод из print в нечитаемой кодировке (прочитала, что это связано с версией питона и, в случае с выдачей частотных словарей, исправить это сложно)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "all_tweets = []\n",
    "for line in open('hw_3_twitter.json', 'r'):\n",
    "    all_tweets.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\xd0\\x9a\\xd0\\xbe\\xd0\\xbb\\xd0\\xb8\\xd1\\x87\\xd0\\xb5\\xd1\\x81\\xd1\\x82\\xd0\\xb2\\xd0\\xbe \\xd1\\x82\\xd0\\xb2\\xd0\\xb8\\xd1\\x82\\xd0\\xbe\\xd0\\xb2 - ', 2556)\n"
     ]
    }
   ],
   "source": [
    "print('Количество твитов - ', len(all_tweets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Посчитать процент удаленных твитов\n",
    "\n",
    "Смотрю, есть ли 'delete' в ключах, если он есть, то увеличиваю кол-во удаленных твитов. del_num - кол-во удаленных твитов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_num = 0\n",
    "for tweet in all_tweets:\n",
    "    keys = list(tweet)\n",
    "    if 'delete' in keys:\n",
    "            del_num += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\xd0\\x9f\\xd1\\x80\\xd0\\xbe\\xd1\\x86\\xd0\\xb5\\xd0\\xbd\\xd1\\x82 \\xd1\\x83\\xd0\\xb4\\xd0\\xb0\\xd0\\xbb\\xd0\\xb5\\xd0\\xbd\\xd0\\xbd\\xd1\\x8b\\xd1\\x85 \\xd1\\x82\\xd0\\xb2\\xd0\\xb8\\xd1\\x82\\xd0\\xbe\\xd0\\xb2 - ', 14)\n"
     ]
    }
   ],
   "source": [
    "print('Процент удаленных твитов - ', del_num*100/len(all_tweets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Оставляем только неудаленные твиты для следующих заданий\n",
    "\n",
    "Проходимся по твитам и смотрим, есть ли у них в ключах 'delete', таким образом отфильтровывая удаленные. tweets - список только из неудаленных твитов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for tweet in all_tweets:\n",
    "    keys = list(tweet)\n",
    "    if 'delete' not in keys:\n",
    "        tweets.append(tweet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Вывести топ-10 самых популярных языков\n",
    "\n",
    "Прохожусь по неудаленным твитам, определяю языки, на которых они написаны, и составляю из них частотный словарь. После этого сортирую его по значениям и вывожу топ-10 языков.langs - список языков всех твитов, lang_dict - частотный словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "langs = []\n",
    "for tweet in tweets:\n",
    "    langs.append(tweet['lang'])\n",
    "lang_dict = Counter(langs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые популярные языки:\n",
      "(u'en', ' ', 719)\n",
      "(u'ja', ' ', 438)\n",
      "(u'es', ' ', 173)\n",
      "(u'ko', ' ', 149)\n",
      "(u'th', ' ', 123)\n",
      "(u'ar', ' ', 119)\n",
      "(u'und', ' ', 117)\n",
      "(u'in', ' ', 71)\n",
      "(u'pt', ' ', 69)\n",
      "(u'fr', ' ', 35)\n"
     ]
    }
   ],
   "source": [
    "print('Самые популярные языки:')\n",
    "k = 0\n",
    "for lang in sorted(lang_dict, key=lang_dict.get, reverse=True):\n",
    "    print(lang, ' ', lang_dict[lang])\n",
    "    k += 1\n",
    "    if k == 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Определить, есть ли пользователи, написавшие несколько твитов, и сколько их\n",
    "\n",
    "Снова прохожусь по неудаленным твитам, создаю частотный словарь пользователей - users_dict. После этого смотрю на значения в словаре и, если значение больше 1, увеличиваю число несколько раз писавших пользователей. user_num - число таких пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "user_num = 0\n",
    "for tweet in tweets:\n",
    "    keys = list(tweet)\n",
    "    if 'delete' not in keys:\n",
    "        users.append(tweet['user']['id'])\n",
    "users_dict = Counter(users)\n",
    "for user in users_dict:\n",
    "    if users_dict[user] > 1:\n",
    "        user_num += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\xd0\\x95\\xd1\\x81\\xd1\\x82\\xd1\\x8c \\xd0\\xbf\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c\\xd0\\xb7\\xd0\\xbe\\xd0\\xb2\\xd0\\xb0\\xd1\\x82\\xd0\\xb5\\xd0\\xbb\\xd0\\xb8, \\xd0\\xbf\\xd0\\xb8\\xd1\\x81\\xd0\\xb0\\xd0\\xb2\\xd1\\x88\\xd0\\xb8\\xd0\\xb5 \\xd0\\xbd\\xd0\\xb5\\xd1\\x81\\xd0\\xba\\xd0\\xbe\\xd0\\xbb\\xd1\\x8c\\xd0\\xba\\xd0\\xbe \\xd1\\x82\\xd0\\xb2\\xd0\\xb8\\xd1\\x82\\xd0\\xbe\\xd0\\xb2. \\xd0\\x92\\xd1\\x81\\xd0\\xb5\\xd0\\xb3\\xd0\\xbe \\xd0\\xb8\\xd1\\x85 ', 25)\n"
     ]
    }
   ],
   "source": [
    "if user_num == 0:\n",
    "    print('Нет пользователей, писавших несколько твитов')\n",
    "else:\n",
    "    print('Есть пользователи, писавшие несколько твитов. Всего их ', user_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Вывести топ-20 пользователей\n",
    "\n",
    "Делаю почти то же самое, что и с языками, но теперь в одном твите может быть несколько хэштегов, поэтому нужен еще один цикл. hashs_dict - частотный словарь хэштегов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashs = []\n",
    "for tweet in tweets:\n",
    "    for hasht in tweet['entities']['hashtags']:\n",
    "        hashs.append(hasht['text'])\n",
    "hashs_dict = Counter(hashs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые популярные хэштеги:\n",
      "(u'BTS', ' ', 17)\n",
      "(u'\\ubc29\\ud0c4\\uc18c\\ub144\\ub2e8', ' ', 13)\n",
      "(u'AMAs', ' ', 11)\n",
      "(u'\\u4eba\\u6c17\\u6295\\u7968\\u30ac\\u30c1\\u30e3', ' ', 8)\n",
      "(u'\\ud0dc\\ud615', ' ', 7)\n",
      "(u'\\ubdd4', ' ', 6)\n",
      "(u'BTSLoveYourselfTour', ' ', 5)\n",
      "(u'PledgeForSwachhBharat', ' ', 5)\n",
      "(u'MPN', ' ', 5)\n",
      "(u'\\uc624\\ub298\\uc758\\ubc29\\ud0c4', ' ', 5)\n",
      "(u'BTSinChicago', ' ', 5)\n",
      "(u'V', ' ', 4)\n",
      "(u'\\u0e40\\u0e1b\\u0e4a\\u0e01\\u0e1c\\u0e25\\u0e34\\u0e15\\u0e42\\u0e0a\\u0e04', ' ', 4)\n",
      "(u'\\uc2dc\\uce74\\uace01\\ud68c\\ucc28\\uacf5\\uc5f0', ' ', 4)\n",
      "(u'JIMIN', ' ', 4)\n",
      "(u'PCAs', ' ', 4)\n",
      "(u'NCT', ' ', 3)\n",
      "(u'WajahmuPlastik', ' ', 3)\n",
      "(u'running', ' ', 3)\n",
      "(u'\\uc9c0\\ubbfc', ' ', 3)\n"
     ]
    }
   ],
   "source": [
    "print('Самые популярные хэштеги:')\n",
    "k = 0\n",
    "for has in sorted(hashs_dict, key=hashs_dict.get, reverse=True):\n",
    "    print(has, ' ', hashs_dict[has])\n",
    "    k += 1\n",
    "    if k == 20:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Сделать частотный словарь из слов, используемых в оригинальных английских твитах.\n",
    "\n",
    "Прохожусь по неудаленным твитам, отфильтровывая ретвитнутые и написанные не на английском. Текст каждого твита очищаю от знаков препинания и делю по пробелам. Потом составляю частотный словарь из слов - words_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "words = []\n",
    "for tweet in tweets:\n",
    "    keys = list(tweet)\n",
    "    if tweet['lang'] == 'en' and 'retweeted_status' not in keys:\n",
    "        tweet_words = tweet['text'].split(' ')\n",
    "        for tword in tweet_words:\n",
    "            if tword != '':\n",
    "                new_word = tword.strip(punctuation).lower()\n",
    "                words.append(new_word)\n",
    "words_dict = Counter(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые популярные слова:\n",
      "(u'the', ' ', 122)\n",
      "(u'to', ' ', 86)\n",
      "(u'a', ' ', 75)\n",
      "(u'i', ' ', 72)\n",
      "(u'and', ' ', 63)\n",
      "(u'is', ' ', 50)\n",
      "(u'you', ' ', 47)\n",
      "(u'of', ' ', 45)\n",
      "(u'it', ' ', 41)\n",
      "(u'for', ' ', 41)\n",
      "(u'in', ' ', 36)\n",
      "(u'that', ' ', 33)\n",
      "(u'this', ' ', 31)\n",
      "(u'my', ' ', 30)\n",
      "(u'be', ' ', 26)\n",
      "(u'on', ' ', 25)\n",
      "(u'me', ' ', 24)\n",
      "(u'are', ' ', 21)\n",
      "(u'with', ' ', 20)\n",
      "(u'what', ' ', 20)\n"
     ]
    }
   ],
   "source": [
    "print('Самые популярные слова:')\n",
    "k = 0\n",
    "for word in sorted(words_dict, key=words_dict.get, reverse=True):\n",
    "    if word != '':\n",
    "        print(word, ' ', words_dict[word])\n",
    "        k += 1\n",
    "    if k == 20:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Вывести топ-20 пользователей с наибольшим количеством подписчиков\n",
    "\n",
    "Прохожусь по неудаленным твитам, создаю словарь, в котором ключи - это имена пользователей, а значения - кол-во их подписчиков. Потом сортирую словарь и вывожу в нужном порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers = {}\n",
    "for tweet in tweets:\n",
    "        name = tweet['user']['screen_name']\n",
    "        followers[name] = tweet['user']['followers_count']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые популярные пользователи:\n",
      "(u'FIL0S0FIA', ' ', 2521403)\n",
      "(u'FitnessMagazine', ' ', 1491309)\n",
      "(u'malaysiakini', ' ', 1206759)\n",
      "(u'NYTScience', ' ', 1137374)\n",
      "(u'GramaticaReal', ' ', 625463)\n",
      "(u'tgrthabertv', ' ', 392472)\n",
      "(u'TheSunFootball', ' ', 383698)\n",
      "(u'Melbourne', ' ', 374222)\n",
      "(u'Roznama_Express', ' ', 318189)\n",
      "(u'burger_boogie', ' ', 311319)\n",
      "(u'PTJASAMARGA', ' ', 273225)\n",
      "(u'BlLLIONAIRES', ' ', 213084)\n",
      "(u'TVGroove', ' ', 165435)\n",
      "(u'dominos_JP', ' ', 149147)\n",
      "(u'Dotmsr', ' ', 146625)\n",
      "(u'RedditCFB', ' ', 144368)\n",
      "(u'maasm909', ' ', 132059)\n",
      "(u'malaymail', ' ', 120474)\n",
      "(u'kapsology', ' ', 109634)\n",
      "(u'auxanodesigns', ' ', 108714)\n"
     ]
    }
   ],
   "source": [
    "print('Самые популярные пользователи:')\n",
    "k = 0\n",
    "for usr in sorted(followers, key=followers.get, reverse=True):\n",
    "    print(usr, ' ', followers[usr])\n",
    "    k += 1\n",
    "    if k == 20:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Вывести топ-10 приложений, с которых написаны твиты\n",
    "\n",
    "Прохожусь по неудаленным твитам, нахожу информацию о приложении и с помощью регулярок чищу название от тегов. После этого составляю частотный словарь из приложений. \n",
    "**Примечание**: арабский нечитаем из-за кодировки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sources = []\n",
    "for tweet in tweets:\n",
    "    source = tweet['source']\n",
    "    pattern = r'rel=\"nofollow\">(.+?)<\\/a>'\n",
    "    app = re.search(pattern, source)\n",
    "    sources.append(app.group(1))\n",
    "sources_dict = Counter(sources)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Twitter for iPhone', ' ', 800)\n",
      "(u'Twitter for Android', ' ', 695)\n",
      "(u'Twitter Web Client', ' ', 140)\n",
      "(u'twittbot.net', ' ', 122)\n",
      "(u'Twitter Lite', ' ', 51)\n",
      "(u'Twitter for iPad', ' ', 28)\n",
      "(u'TweetDeck', ' ', 23)\n",
      "(u'Facebook', ' ', 17)\n",
      "(u'IFTTT', ' ', 14)\n",
      "(u'dlvr.it', ' ', 10)\n",
      "(u'\\u062a\\u0637\\u0628\\u064a\\u0642 \\u0642\\u0631\\u0622\\u0646\\u064a', ' ', 10)\n",
      "(u'Buffer', ' ', 8)\n",
      "(u'Google', ' ', 8)\n",
      "(u'autotweety.net', ' ', 7)\n",
      "(u'Hootsuite Inc.', ' ', 7)\n",
      "(u'WordPress.com', ' ', 6)\n",
      "(u'Twittascope', ' ', 6)\n",
      "(u'Botbird tweets', ' ', 6)\n",
      "(u'Zapier.com', ' ', 5)\n",
      "(u'Hotpepper', ' ', 5)\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for sour in sorted(sources_dict, key=sources_dict.get, reverse=True):\n",
    "    print(sour, ' ', sources_dict[sour])\n",
    "    k += 1\n",
    "    if k == 20:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
